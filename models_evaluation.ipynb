{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBo7mEuqlUSD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.stats import spearmanr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функции"
      ],
      "metadata": {
        "id": "jIxuIAhEm1-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сурс: https://github.com/akutuzov/rushifteval_public/blob/main/evaluation/evaluate.py\n",
        "\n",
        "Функции отредактированы с учетом наших задач."
      ],
      "metadata": {
        "id": "PDokkOdMlcMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ys(model_answers, true_answers, n_answers=3):\n",
        "    \"\"\"\n",
        "    :param model_answers: path to tab-separated answer file (lemma + \"\\t\" + tab-separated scores)\n",
        "    :param true_answers: path to tab-separated gold answer file (lemma + \"\\t\" + tab-separated scores)\n",
        "    :param n_answers: how many scores (time period pairs) for each word?\n",
        "    :return: a list of the model scores, and one for the true scores\n",
        "    \"\"\"\n",
        "    y_hat_tmp = {}\n",
        "    errors = 0\n",
        "    with open(model_answers, \"r\") as f_in:\n",
        "        for line in f_in:\n",
        "            res = line.strip().split(\"\\t\")\n",
        "            lemma = res[0]\n",
        "            y_hat_tmp[lemma] = []\n",
        "            for i in range(n_answers):\n",
        "                score = res[1 + i]\n",
        "                if score == \"nan\":\n",
        "                    errors += 1\n",
        "                y_hat_tmp[lemma].append(float(score))\n",
        "    if errors:\n",
        "        print(\"Found %d NaN predictions\" % errors, file=sys.stderr)\n",
        "    y_hat, y = [], []\n",
        "    with open(true_answers, \"r\") as f_in:\n",
        "        for line in f_in:\n",
        "            res = line.strip().split(\"\\t\")\n",
        "            lemma = res[0]\n",
        "            scores = []\n",
        "            for i in range(n_answers):\n",
        "                score = res[1 + i]\n",
        "                scores.append(float(score))\n",
        "            try:\n",
        "                predicted_answer = y_hat_tmp[lemma]\n",
        "            except KeyError:\n",
        "                raise SystemExit(\"Error: the word %s not found in the submission!\" % lemma)\n",
        "            assert len(predicted_answer) == len(scores)\n",
        "            y.append(scores)\n",
        "            y_hat.append(predicted_answer)\n",
        "\n",
        "    return y_hat, y"
      ],
      "metadata": {
        "id": "ERkJ_MY6lnxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model_answers, true_answers):\n",
        "    \"\"\"\n",
        "    Computes the Spearman's correlation coefficient against the true rank as annotated by humans\n",
        "    :param model_answers: list of scores' lists\n",
        "    :param true_answers: list of scores' lists\n",
        "    :return: (Spearman's correlation coefficient, p-value)\n",
        "    \"\"\"\n",
        "    assert len(model_answers[0]) == len(true_answers[0])\n",
        "    nr_scores = len(true_answers[0])\n",
        "    correlations = []\n",
        "    for i in range(nr_scores):\n",
        "        cur_preds = [el[i] for el in model_answers]\n",
        "        cur_golds = [el[i] for el in true_answers]\n",
        "        r, p = spearmanr(cur_preds, cur_golds, nan_policy=\"omit\")\n",
        "        correlations.append((r, p))\n",
        "    return correlations"
      ],
      "metadata": {
        "id": "nwNrB3NSlqdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_scores(pred_file, truth_file, output_file):\n",
        "    \"\"\"\n",
        "    Evaluate a model and save the scores in a .txt file.\n",
        "    \"\"\"\n",
        "    predictions, gold = get_ys(pred_file, truth_file)\n",
        "    res = evaluation(predictions, gold)\n",
        "    ave_score = (res[0][0] + res[1][0] + res[2][0]) / 3\n",
        "\n",
        "    print(\"Spearman rho score 0: {:.3f}  p: {:.3f}\".format(res[0][0], res[0][1]))\n",
        "    print(\"Spearman rho score 1: {:.3f}  p: {:.3f}\".format(res[1][0], res[1][1]))\n",
        "    print(\"Spearman rho score 2: {:.3f}  p: {:.3f}\".format(res[2][0], res[2][1]))\n",
        "    print(\"Average score: {:.3f}\".format(ave_score))\n",
        "\n",
        "    with open(output_file, 'w', encoding=\"utf-8\") as f:\n",
        "        f.write(\"spearman0: {:.3f}\\n\".format(res[0][0]))\n",
        "        f.write(\"spearman1: {:.3f}\\n\".format(res[1][0]))\n",
        "        f.write(\"spearman2: {:.3f}\\n\".format(res[2][0]))\n",
        "        f.write(\"ave_score: {:.3f}\\n\".format(ave_score))"
      ],
      "metadata": {
        "id": "RrmTrziKlspI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Скачиваем предсказания"
      ],
      "metadata": {
        "id": "DrKbIvyDuByb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/predictions\n",
        "!mkdir /content/targets\n",
        "!mkdir /content/scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4rf-TyIn8Xv",
        "outputId": "2b2f97d5-5eab-489f-ad59-330613a12503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/predictions’: File exists\n",
            "mkdir: cannot create directory ‘/content/targets’: File exists\n",
            "mkdir: cannot create directory ‘/content/scores’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/predictions/predictions_w2v.tsv https://raw.githubusercontent.com/eanor/nlp_project_2024/main/predictions/prediction_w2v.tsv\n",
        "!wget -O /content/predictions/predictions_bert.tsv https://raw.githubusercontent.com/eanor/nlp_project_2024/main/predictions/prediction_bert.tsv\n",
        "!wget -O /content/predictions/predictions_bert_tiny.tsv https://raw.githubusercontent.com/eanor/nlp_project_2024/main/predictions/prediction_bert_tiny.tsv\n",
        "!wget -O /content/predictions/predictions_chat.tsv https://raw.githubusercontent.com/eanor/nlp_project_2024/main/predictions/prediction_chat.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gexqIrvpm9bi",
        "outputId": "8bad0f9c-56f2-4cfd-9c6d-73a1e4a02419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-24 18:48:55--  https://raw.githubusercontent.com/eanor/nlp_project_2024/main/predictions/prediction_w2v.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8125 (7.9K) [text/plain]\n",
            "Saving to: ‘/content/predictions/predictions_w2v.tsv’\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/prediction 100%[===================>]   7.93K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-24 18:48:55 (60.1 MB/s) - ‘/content/predictions/predictions_w2v.tsv’ saved [8125/8125]\n",
            "\n",
            "--2024-03-24 18:48:55--  https://raw.githubusercontent.com/eanor/nlp_project_2024/main/predictions/prediction_bert.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7318 (7.1K) [text/plain]\n",
            "Saving to: ‘/content/predictions/predictions_bert.tsv’\n",
            "\n",
            "/content/prediction 100%[===================>]   7.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-24 18:48:55 (54.4 MB/s) - ‘/content/predictions/predictions_bert.tsv’ saved [7318/7318]\n",
            "\n",
            "--2024-03-24 18:48:55--  https://raw.githubusercontent.com/eanor/nlp_project_2024/main/predictions/prediction_bert_tiny.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7475 (7.3K) [text/plain]\n",
            "Saving to: ‘/content/predictions/predictions_bert_tiny.tsv’\n",
            "\n",
            "/content/prediction 100%[===================>]   7.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-24 18:48:55 (58.5 MB/s) - ‘/content/predictions/predictions_bert_tiny.tsv’ saved [7475/7475]\n",
            "\n",
            "--2024-03-24 18:48:55--  https://raw.githubusercontent.com/eanor/nlp_project_2024/main/predictions/prediction_chat.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 976 [text/plain]\n",
            "Saving to: ‘/content/predictions/predictions_chat.tsv’\n",
            "\n",
            "/content/prediction 100%[===================>]     976  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-24 18:48:55 (108 MB/s) - ‘/content/predictions/predictions_chat.tsv’ saved [976/976]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/targets/targets.tsv https://raw.githubusercontent.com/akutuzov/rushifteval_public/main/annotated_testset.tsv\n",
        "!wget -O /content/targets/chat_targets.tsv https://raw.githubusercontent.com/eanor/nlp_project_2024/main/models/chat_targets.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tey55j35noRT",
        "outputId": "819c6d4d-5f56-404e-ee1c-ed4a46f7f629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-24 18:48:55--  https://raw.githubusercontent.com/akutuzov/rushifteval_public/main/annotated_testset.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6509 (6.4K) [text/plain]\n",
            "Saving to: ‘/content/targets/targets.tsv’\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/targets/ta 100%[===================>]   6.36K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-24 18:48:55 (39.7 MB/s) - ‘/content/targets/targets.tsv’ saved [6509/6509]\n",
            "\n",
            "--2024-03-24 18:48:55--  https://raw.githubusercontent.com/eanor/nlp_project_2024/main/models/chat_targets.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1294 (1.3K) [text/plain]\n",
            "Saving to: ‘/content/targets/chat_targets.tsv’\n",
            "\n",
            "/content/targets/ch 100%[===================>]   1.26K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-24 18:48:55 (105 MB/s) - ‘/content/targets/chat_targets.tsv’ saved [1294/1294]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_dir = \"/content/predictions/\"\n",
        "targets_dir = \"/content/targets/\"\n",
        "scores_dir = \"/content/scores/\""
      ],
      "metadata": {
        "id": "DB_-84TYltQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ансамбль"
      ],
      "metadata": {
        "id": "Uqpc1uLUt6NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble(m1_preds_fp, m2_preds_fp, output_fp, coef=0.5):\n",
        "    m1_preds, m2_preds = get_ys(m1_preds_fp, m2_preds_fp)\n",
        "    m1_preds, m2_preds = np.array(m1_preds), np.array(m2_preds)\n",
        "\n",
        "    target_words = pd.read_csv(m1_preds_fp, sep=\"\\t\", names=[\"word\", \"score1\", \"score2\", \"score3\"])[\"word\"].to_list()\n",
        "\n",
        "    new_preds = (m1_preds * coef) + (m2_preds * (1 - coef))\n",
        "\n",
        "    new_preds_list = []\n",
        "    for i in range(len(new_preds)):\n",
        "        new_pred = {\n",
        "            \"word\": target_words[i],\n",
        "            \"score1\": new_preds[i][0],\n",
        "            \"score2\": new_preds[i][1],\n",
        "            \"score3\": new_preds[i][2],\n",
        "        }\n",
        "        new_preds_list.append(new_pred)\n",
        "\n",
        "    pd.DataFrame(new_preds_list).to_csv(output_fp, sep=\"\\t\", index=False, header=False)"
      ],
      "metadata": {
        "id": "sxzBqoEvt8IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_fp = preds_dir + \"predictions_w2v.tsv\"\n",
        "bert_fp = preds_dir + \"predictions_bert.tsv\"\n",
        "\n",
        "ensemble_fp = preds_dir + \"predictions_ensemble.tsv\"\n",
        "\n",
        "coef = 0.9996"
      ],
      "metadata": {
        "id": "5onbunUeuRDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble(w2v_fp, bert_fp, ensemble_fp, coef=coef)"
      ],
      "metadata": {
        "id": "4PEoioiRuIKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка"
      ],
      "metadata": {
        "id": "RXYhk3wYm7-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = [\"w2v\", \"bert\", \"bert_tiny\", \"ensemble\", \"chat\"]"
      ],
      "metadata": {
        "id": "kIOagORwtaj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in model_names:\n",
        "\n",
        "    print(model_name + \" scores\")\n",
        "\n",
        "    preds_fp = preds_dir + \"predictions_\" + model_name + \".tsv\"\n",
        "    targets_fp = targets_dir + \"chat_targets.tsv\" if model_name in [\"chat\", \"elmo\"] else targets_dir + \"targets.tsv\"\n",
        "    scores_fp = scores_dir + \"scores_\" + model_name + \".txt\"\n",
        "\n",
        "    save_scores(preds_fp, targets_fp, scores_fp)\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnFaIogKo-S9",
        "outputId": "443743c8-f18f-45aa-e9f1-9bfd1e29b810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w2v scores\n",
            "Spearman rho score 0: 0.230  p: 0.022\n",
            "Spearman rho score 1: 0.343  p: 0.001\n",
            "Spearman rho score 2: 0.236  p: 0.019\n",
            "Average score: 0.269\n",
            "\n",
            "\n",
            "bert scores\n",
            "Spearman rho score 0: 0.208  p: 0.039\n",
            "Spearman rho score 1: 0.250  p: 0.013\n",
            "Spearman rho score 2: 0.020  p: 0.841\n",
            "Average score: 0.159\n",
            "\n",
            "\n",
            "bert_tiny scores\n",
            "Spearman rho score 0: -0.226  p: 0.024\n",
            "Spearman rho score 1: 0.104  p: 0.307\n",
            "Spearman rho score 2: -0.161  p: 0.112\n",
            "Average score: -0.094\n",
            "\n",
            "\n",
            "ensemble scores\n",
            "Spearman rho score 0: 0.260  p: 0.009\n",
            "Spearman rho score 1: 0.369  p: 0.000\n",
            "Spearman rho score 2: 0.239  p: 0.017\n",
            "Average score: 0.290\n",
            "\n",
            "\n",
            "chat scores\n",
            "Spearman rho score 0: -0.166  p: 0.484\n",
            "Spearman rho score 1: -0.104  p: 0.662\n",
            "Spearman rho score 2: 0.189  p: 0.425\n",
            "Average score: -0.027\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}